{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.4.0 transformers==4.46.2 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3678ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade setuptools --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f3959",
   "metadata": {},
   "source": [
    "`pillow==1.25.0` on their [HF page](https://huggingface.co/AIDC-AI/Ovis2-1B) doesnt work with my python; hoping `1.26.4` will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256aaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4 pillow==10.3.0 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn==2.7.0.post2 --no-build-isolation --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97671c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y torchvision --break-system-packages\n",
    "!pip install torchvision --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torchvision safetensors --break-system-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea283b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/AIDC-AI/Ovis2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e8ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cba482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Ovis2-1B\",\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             multimodal_max_length=32768,\n",
    "                                             trust_remote_code=True).cuda()\n",
    "text_tokenizer = model.get_text_tokenizer()\n",
    "visual_tokenizer = model.get_visual_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f849042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-image input\n",
    "image_path = 'example.jpg'\n",
    "images = [Image.open(image_path)]\n",
    "max_partition = 9\n",
    "text = '''\n",
    "      Give the json data format of the slip text inside the image; \n",
    "      give the name of the store the logo shows, the name of the branch separate, \n",
    "      a list of items purchased that has the cost to the right of the row, \n",
    "      and the final total the slip shows.'''\n",
    "query = f'<image>\\n{text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ae592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format conversation\n",
    "prompt, input_ids, pixel_values = model.preprocess_inputs(query, images, max_partition=max_partition)\n",
    "attention_mask = torch.ne(input_ids, text_tokenizer.pad_token_id)\n",
    "input_ids = input_ids.unsqueeze(0).to(device=model.device)\n",
    "attention_mask = attention_mask.unsqueeze(0).to(device=model.device)\n",
    "if pixel_values is not None:\n",
    "    pixel_values = pixel_values.to(dtype=visual_tokenizer.dtype, device=visual_tokenizer.device)\n",
    "pixel_values = [pixel_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab98b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"storeName\": \"Pick n Pay\", \"branchName\": \"Mini Market Oakdene\", \"itemsPurchased\": [\"SOUP PACK\", \"ALMONDS SLICED 100GR\", \"5% Pensioners Discount5.0%\"], \"total\": 54.13}\n"
     ]
    }
   ],
   "source": [
    "# generate output\n",
    "with torch.inference_mode():\n",
    "    gen_kwargs = dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        top_p=None,\n",
    "        top_k=None,\n",
    "        temperature=None,\n",
    "        repetition_penalty=None,\n",
    "        eos_token_id=model.generation_config.eos_token_id,\n",
    "        pad_token_id=text_tokenizer.pad_token_id,\n",
    "        use_cache=True\n",
    "    )\n",
    "    output_ids = model.generate(input_ids, pixel_values=pixel_values, attention_mask=attention_mask, **gen_kwargs)[0]\n",
    "    output = text_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    print(f'{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618c82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
