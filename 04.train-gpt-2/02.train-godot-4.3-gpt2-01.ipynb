{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7762b933",
   "metadata": {},
   "source": [
    "# Version 2: Train Godot 4.3 - GPT2\n",
    "\n",
    "## Plan:\n",
    "\n",
    "Train [edg3/godot-4.3-gpt2](https://huggingface.co/edg3/godot-4.3-gpt2) on the text off of the **Godot 4.3** documentation further.\n",
    "\n",
    "### System Used\n",
    "\n",
    "This was done on older desktop hardware. Windows 10, WSL Ubuntu 22.04, i7 processor, Radeon 3050 8Gb OC, 16Gb RAM.\n",
    "\n",
    "### Warning:\n",
    "\n",
    "**Things are changing regularly, so if you try this yourself you will see warnings (if it still runs), mostly to do with deprecation these days.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee299d",
   "metadata": {},
   "source": [
    "### Base Code Use\n",
    "\n",
    "Used as a starter: [311_fine_tuning_GPT2.ipynb](https://github.com/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb)\n",
    "\n",
    "Used (adjusted) for further training: (this) built off of [02.train-godot-4.3-gpt2.ipynb](https://github.com/edg3/GPT-systems/blob/main/04.train-gpt-2/02.train-godot-4.3-gpt2.ipynb)\n",
    "\n",
    "Note: ```--break-system-packages``` is required for my customised WSL2 instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b49d4a",
   "metadata": {},
   "source": [
    "## Step 1: Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96df4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q transformers torch datasets python-docx --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fa72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU PyPDF2 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17550e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af9eb3",
   "metadata": {},
   "source": [
    "## Step 2: Setup training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e04317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 05:14:23.587088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 05:14:24.215690: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 05:14:24.519163: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 05:14:25.808872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 05:14:34.594563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7659a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb73be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b2cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d5f00",
   "metadata": {},
   "source": [
    "## Step 3: Specify Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554aca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"./train-smart.txt\"\n",
    "model_name = 'edg3/godot-4.3-gpt2'\n",
    "output_dir = './model'\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 25.0 # Should take around 4h30m in theory\n",
    "save_steps = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29d14e",
   "metadata": {},
   "source": [
    "#### Step 3.1: I didn't want to use WANDB, this is how you disable it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e952d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't want to use wandb\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5477e10",
   "metadata": {},
   "source": [
    "## Step 4: Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beccf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b30ff25075c41539bf288e854086214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58c3c7a72f64cf5a8deecc1caea6ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1adbd796564ecaac5f724cf082c02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9b1b7bbd04ce388676e6efc010233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edg3/.local/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc90694838e94028b457cec819b71fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/912 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef6130e844f447ab522acc2b5736523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c817e3437e84b5890bbe5c757d74c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='357' max='157450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   357/157450 01:34 < 11:34:34, 3.77 it/s, Epoch 0.06/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961cd18",
   "metadata": {},
   "source": [
    "## Step 5: Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "model1_path = \"./model\"\n",
    "max_length = 512\n",
    "\n",
    "model = load_model(model1_path)\n",
    "tokenizer = load_tokenizer(model1_path)\n",
    "\n",
    "def generate_text(sequence):\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acabbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query(question1):\n",
    "    generate_text(model1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7430573",
   "metadata": {},
   "source": [
    "### 6.1: Whatâ€™s new in Godot 4.3 compared to previous versions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Whatâ€™s new in Godot 4.3 compared to previous versions?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd23710",
   "metadata": {},
   "source": [
    "### 6.2: Can you explain the changes in the rendering pipeline introduced in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460754c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you explain the changes in the rendering pipeline introduced in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c503ae5",
   "metadata": {},
   "source": [
    "### 6.3: How do you implement a custom shader in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How do you implement a custom shader in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f6165",
   "metadata": {},
   "source": [
    "### 6.4: What are the key differences between GDScript and C# in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the key differences between GDScript and C# in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2235f",
   "metadata": {},
   "source": [
    "### 6.5: How would you optimize a game for performance in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How would you optimize a game for performance in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0e94d",
   "metadata": {},
   "source": [
    "### 6.6: Can you describe the process of creating a custom node in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you describe the process of creating a custom node in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba91fb",
   "metadata": {},
   "source": [
    "### 6.7: What are the new features in the animation system of Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the new features in the animation system of Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926c86c",
   "metadata": {},
   "source": [
    "### 6.8: How do you handle input events in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How do you handle input events in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f27cc",
   "metadata": {},
   "source": [
    "### 6.9: What are the best practices for using the new navigation system in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7638af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the best practices for using the new navigation system in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e74d78",
   "metadata": {},
   "source": [
    "### 6.10: Can you walk me through setting up a multiplayer game in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you walk me through setting up a multiplayer game in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9f66c",
   "metadata": {},
   "source": [
    "### 6.11: How can I use C# to create a procedurally generated 3D chunk in a node in Godot 4.3 on its own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How can I use C# to create a procedurally generated 3D chunk in a node in Godot 4.3 on its own?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15dad",
   "metadata": {},
   "source": [
    "### 6.12: How can I make nodes used as chunks, similar to minecraft, to store data in Godot 4.3 so that I can create a synchronous multiplayer world that can be hosted by 1 player, and have a second player connect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How can I make nodes used as chunks, similar to minecraft, to store data in Godot 4.3 so that I can create a synchronous multiplayer world that can be hosted by 1 player, and have a second player connect?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d7861",
   "metadata": {},
   "source": [
    "### 6.13: In Godot 4.3, using C#, can you create 2D snake from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('In Godot 4.3, using C#, can you create 2D snake from scratch?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84621c98",
   "metadata": {},
   "source": [
    "# Review (Personal):\n",
    "\n",
    "*Note: I need to sort out tokens; only thought of it after starting training v1*\n",
    "\n",
    "- The training only got to steps around 62k / 100k and at 0.460700 training loss I'm undecided on if this was a smart plan with GPT2, it's highly hallucinating. Will experiment further and see where it gets to.\n",
    "\n",
    "I believe this first training step, which crashed at around 62% complete, is along the correct lines. Now to work out how to train it further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008eed41",
   "metadata": {},
   "source": [
    "# Step 7: Upload to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q huggingface_hub --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857383ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import create_repo\n",
    "import os\n",
    "\n",
    "# Define your model path and repository name\n",
    "model_path = \"model/\"\n",
    "repo_name = \"edg3/godot-4.3-gpt2\"\n",
    "my_token = '<your-token-here>' \n",
    "\n",
    "if False: # first time true, else repo exists make false\n",
    "    create_repo(repo_name, token=my_token)\n",
    "\n",
    "# List all directories inside the model path\n",
    "folders = [f for f in os.listdir(model_path) if os.path.isdir(os.path.join(model_path, f))]\n",
    "skip_check = False\n",
    "\n",
    "# Print the list of folders\n",
    "if folders and not skip_check:\n",
    "    print(\"Folders inside 'model/':\")\n",
    "    for folder in folders:\n",
    "        print(folder)\n",
    "else:\n",
    "    # Initialize the API\n",
    "    api = HfApi()\n",
    "\n",
    "    # Upload the model\n",
    "    api.upload_folder(\n",
    "        folder_path=model_path,\n",
    "        repo_id=repo_name,\n",
    "        commit_message=\"Second training\",\n",
    "        token=my_token\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5674a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
