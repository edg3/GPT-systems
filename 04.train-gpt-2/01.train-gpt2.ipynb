{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7762b933",
   "metadata": {},
   "source": [
    "# Version 1: Train GPT2\n",
    "\n",
    "## Plan:\n",
    "\n",
    "Train GPT2 on the text off of the **Godot 4.3** documentation for 5 epochs, then test the model.\n",
    "\n",
    "### System Used\n",
    "\n",
    "This was done on older desktop hardware. Windows 10, WSL Ubuntu 22.04, i7 processor, Radeon 3050 8Gb OC, 16Gb RAM.\n",
    "\n",
    "### Warning:\n",
    "\n",
    "**Things are changing regularly, and you will see warnings (if this still runs), mostly to do with deprecation. This means, eventually, one day this code will need changes/updates/rewrites.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee299d",
   "metadata": {},
   "source": [
    "### Base Code Use\n",
    "\n",
    "Used as a starter: [311_fine_tuning_GPT2.ipynb](https://github.com/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb)\n",
    "\n",
    "Note: ```--break-system-packages``` is required for my customised WSL2 instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b49d4a",
   "metadata": {},
   "source": [
    "## Step 1: Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96df4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch datasets python-docx --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fa72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU PyPDF2 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17550e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fce57d",
   "metadata": {},
   "source": [
    "## Step 2: Define file text extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read different file types\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text\n",
    "\n",
    "def read_word(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def read_documents_from_directory(directory):\n",
    "    combined_text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            combined_text += read_pdf(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            combined_text += read_word(file_path)\n",
    "        elif filename.endswith(\".txt\"):\n",
    "            combined_text += read_txt(file_path)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bd757",
   "metadata": {},
   "source": [
    "## Step 3: Prepare text Godot 4.3 Text (sample version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7983e5",
   "metadata": {},
   "source": [
    "Got ```godot-docs``` through ```https://docs.godotengine.org/en/stable/index.html``` using the ```stable``` variety. As of today it's ```319mb```.\n",
    "\n",
    "Extract contents into ```godot-docs-html-stable``` then run below to extract data from the html (dirty formatting for v1).\n",
    "\n",
    "**Time Required:** ~4min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00559bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert html files recursively into txt files without format\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def convert_html_to_txt(html_file_path, txt_file_path):\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as html_file:\n",
    "        soup = BeautifulSoup(html_file, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        \n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)\n",
    "\n",
    "def process_folder(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.html'):\n",
    "                #print('processing:',file)\n",
    "                html_file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(html_file_path, input_folder)\n",
    "                txt_file_path = os.path.join(output_folder, os.path.splitext(relative_path)[0] + '.txt')\n",
    "                splt_path = txt_file_path.split('/')\n",
    "                #print(splt_path[-1])\n",
    "                splt_path[-1] = splt_path[-2] + '-' + splt_path[-1]\n",
    "                convert_html_to_txt(html_file_path, output_folder + '/' + splt_path[-1])\n",
    "            else:\n",
    "                print(' - skipped:',file)\n",
    "\n",
    "input_folder = 'godot-docs-html-stable/tutorials'\n",
    "output_folder = 'godot-docs-text'\n",
    "\n",
    "process_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07c35f",
   "metadata": {},
   "source": [
    "## Step 4: Trim excess whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read documents from the directory\n",
    "train_directory = output_folder\n",
    "text_data = read_documents_from_directory(train_directory)\n",
    "text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_data[0:200],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6471ef",
   "metadata": {},
   "source": [
    "*Uncomment this with train.txt removed to write a new train.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only needed once off if you have the data\n",
    "#with open(\"./train.txt\", \"w\") as f:\n",
    "#    f.write(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a439965",
   "metadata": {},
   "source": [
    "### 4.1: Minimised train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00693611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        for line in lines:\n",
    "            if len(line.strip()) > 30:\n",
    "                file.write(line)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'train.txt'\n",
    "output_file = 'train-minimised.txt'\n",
    "filter_lines(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af9eb3",
   "metadata": {},
   "source": [
    "## Step 5: Setup training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e04317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7659a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d5f00",
   "metadata": {},
   "source": [
    "## Step 6: Specify Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554aca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"./train-manual.txt\"\n",
    "model_name = 'gpt2'\n",
    "output_dir = './model'\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 5.0\n",
    "save_steps = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29d14e",
   "metadata": {},
   "source": [
    "#### Step 6.1: I didn't want to use WANDB, this is how you disable it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't want to use wandb\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5477e10",
   "metadata": {},
   "source": [
    "## Step 7: Run the training\n",
    "\n",
    "*Note: on my desktop the 5 epochs was what I felt like trying out, ~it shared it would take around 5 hours at the start~ ~the minimised data shared it would take 45 minutes~ manual first test mode, without much in training, took 8 seconds.*\n",
    "\n",
    "Minimised data is super messy, I need to format training data way better. This will likely give hulucinations that are similar to what I'm looking for.\n",
    "\n",
    "Also used:\n",
    "\n",
    "- ```git lfs track \"*.safetensors\"```\n",
    "- ```git lfs track \"*.gguf\"```\n",
    "\n",
    "This was for a later stage if I want to upload them to my repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beccf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47dcb8",
   "metadata": {},
   "source": [
    "*Note: Kernel restart once here, then did Step 8. This was to free up GPU memory for the tests below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961cd18",
   "metadata": {},
   "source": [
    "## Step 8: Test The Model\n",
    "\n",
    "*Warning: This data isn't likely to give the style of answers we would love to have, but the plan is to test if the idea I'm working on will succeed, or not. If the answers below hint at it being possible,* **Version 2** *will follow this starting structure with my idea of a revamp.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "model1_path = \"./model\"\n",
    "max_length = 512\n",
    "\n",
    "model = load_model(model1_path)\n",
    "tokenizer = load_tokenizer(model1_path)\n",
    "\n",
    "def generate_text(sequence):\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acabbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query(question1):\n",
    "    generate_text(model1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7430573",
   "metadata": {},
   "source": [
    "### 8.1: What’s new in Godot 4.3 compared to previous versions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What’s new in Godot 4.3 compared to previous versions?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd23710",
   "metadata": {},
   "source": [
    "### 8.2: Can you explain the changes in the rendering pipeline introduced in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460754c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you explain the changes in the rendering pipeline introduced in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c503ae5",
   "metadata": {},
   "source": [
    "### 8.3: How do you implement a custom shader in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How do you implement a custom shader in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f6165",
   "metadata": {},
   "source": [
    "### 8.4: What are the key differences between GDScript and C# in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the key differences between GDScript and C# in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2235f",
   "metadata": {},
   "source": [
    "### 8.5: How would you optimize a game for performance in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How would you optimize a game for performance in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0e94d",
   "metadata": {},
   "source": [
    "### 8.6: Can you describe the process of creating a custom node in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you describe the process of creating a custom node in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba91fb",
   "metadata": {},
   "source": [
    "### 8.7: What are the new features in the animation system of Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the new features in the animation system of Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926c86c",
   "metadata": {},
   "source": [
    "### 8.8: How do you handle input events in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How do you handle input events in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f27cc",
   "metadata": {},
   "source": [
    "### 8.9: What are the best practices for using the new navigation system in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7638af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('What are the best practices for using the new navigation system in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e74d78",
   "metadata": {},
   "source": [
    "### 8.10: Can you walk me through setting up a multiplayer game in Godot 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Can you walk me through setting up a multiplayer game in Godot 4.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9f66c",
   "metadata": {},
   "source": [
    "### 8.11: How can I use C# to create a procedurally generated 3D chunk in a node in Godot 4.3 on its own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How can I use C# to create a procedurally generated 3D chunk in a node in Godot 4.3 on its own?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15dad",
   "metadata": {},
   "source": [
    "### 8.12: How can I make nodes used as chunks, similar to minecraft, to store data in Godot 4.3 so that I can create a synchronous multiplayer world that can be hosted by 1 player, and have a second player connect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('How can I make nodes used as chunks, similar to minecraft, to store data in Godot 4.3 so that I can create a synchronous multiplayer world that can be hosted by 1 player, and have a second player connect?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d7861",
   "metadata": {},
   "source": [
    "### 8.13: In Godot 4.3, using C#, can you create 2D snake from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('In Godot 4.3, using C#, can you create 2D snake from scratch?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84621c98",
   "metadata": {},
   "source": [
    "# Review (Personal):\n",
    "\n",
    "- **Test 1:** 0/13 - 100% faliure on first run. I'm thinking I need to adjust ```train.txt``` to filter out useless rows. I think the contents wraps too close in each category. That might be why Training Loss was way too high. Cleaning the model folder, revamp of data to train on manually, then will run tests again.\n",
    "- **Test 2:** 0/13 - 100% failure again. Rethinking it, going to test with just the one section of the documentation manually as a training set. ```./train-minimised.txt``` is still too dirty to possibly have any good results.\n",
    "- **Test 3:** 2.5ish/13 - classing it as about 80% fail and just giving small points for some of the answer text. My training data was way too small in ```./train-manual.txt```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5617e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
